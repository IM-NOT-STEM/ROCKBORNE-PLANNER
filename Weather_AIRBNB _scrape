from dotenv import load_dotenv, find_dotenv
load_dotenv(find_dotenv(), override=True)

import os, re, io, gzip, urllib.parse, unicodedata, requests, pandas as pd
import gradio as gr
from bs4 import BeautifulSoup

# ================== Config ==================
DEFAULT_DEST = "Canc√∫n, Mexico"
CATEGORIES = ["nightclubs","restaurants","bars","live music","beach clubs","cafes"]
UNITS = ["METRIC","IMPERIAL"]
INSIDE_AIRBNB_INDEX = "https://insideairbnb.com/get-the-data/"
UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36"
HDR = {"User-Agent": UA, "Accept-Language": "en"}

# ================== Google Maps Embed (unchanged) ==================
def build_embed_url(destination: str, category: str, zoom: int = 13, maptype: str = "roadmap") -> str:
    api_key = os.getenv("GOOGLE_MAPS_API_KEY", "")
    if not api_key: return ""
    q = f"{category} near {destination}".strip()
    q_enc = urllib.parse.quote(q)
    return f"https://www.google.com/maps/embed/v1/search?key={api_key}&q={q_enc}&zoom={zoom}&maptype={maptype}"

def make_iframe(url: str, height: int = 600) -> str:
    if not url:
        return "<div style='color:red;padding:1rem'>Error: Missing GOOGLE_MAPS_API_KEY environment variable.</div>"
    return f"""<iframe width="100%" height="{height}" frameborder="0" style="border:0"
      referrerpolicy="no-referrer-when-downgrade" allowfullscreen src="{url}"></iframe>"""

# ================== Geocode (OSM Nominatim) ==================
def geocode_destination(dest: str):
    r = requests.get(
        "https://nominatim.openstreetmap.org/search",
        params={"q": dest, "format": "json", "limit": 1, "addressdetails": 1},
        headers={"User-Agent": "holiday-planner/1.0"},
        timeout=15,
    )
    r.raise_for_status()
    arr = r.json()
    if not arr: return None
    x = arr[0]; addr = x.get("address", {})
    return {
        "lat": float(x["lat"]), "lon": float(x["lon"]),
        "display_name": x.get("display_name", dest),
        "country": addr.get("country",""), "country_code": (addr.get("country_code") or "").upper(),
        "city_like": addr.get("city") or addr.get("town") or addr.get("village") or dest
    }

# ================== Google Weather API (no scraping) ==================
def _gw_key():
    k = os.getenv("GOOGLE_MAPS_API_KEY", "")
    if not k: raise RuntimeError("GOOGLE_MAPS_API_KEY not set")
    return k

def google_weather_current(lat: float, lon: float, units_system="METRIC"):
    url = "https://weather.googleapis.com/v1/currentConditions:lookup"
    r = requests.get(url, params={
        "key": _gw_key(),
        "location.latitude": lat,
        "location.longitude": lon,
        "unitsSystem": units_system,
    }, timeout=15)
    r.raise_for_status()
    j = r.json()
    wind = (j.get("wind") or {})
    speed = (wind.get("speed") or {}).get("value")
    gust  = (wind.get("gust") or {}).get("value")
    out = {
        "temp": (j.get("temperature") or {}).get("degrees"),
        "feels_like": (j.get("feelsLikeTemperature") or {}).get("degrees"),
        "humidity": j.get("relativeHumidity"),
        "cloud_cover": j.get("cloudCover"),
        "condition": ((j.get("weatherCondition") or {}).get("description") or {}).get("text"),
        "wind_kmh": speed if units_system=="METRIC" else None,
        "wind_mph": speed if units_system=="IMPERIAL" else None,
        "gust_kmh": gust if units_system=="METRIC" else None,
        "gust_mph": gust if units_system=="IMPERIAL" else None,
        "pressure_mbar": (j.get("airPressure") or {}).get("meanSeaLevelMillibars"),
        "uv_index": j.get("uvIndex"),
        "precip_prob": ((j.get("precipitation") or {}).get("probability") or {}).get("percent"),
    }
    return out

def google_weather_daily(lat: float, lon: float, days=5, units_system="METRIC"):
    url = "https://weather.googleapis.com/v1/forecast/days:lookup"
    r = requests.get(url, params={
        "key": _gw_key(),
        "location.latitude": lat,
        "location.longitude": lon,
        "days": max(1, min(days, 10)),
        "unitsSystem": units_system,
    }, timeout=15)
    r.raise_for_status()
    j = r.json()
    out = []
    for d in j.get("forecastDays", []):
        dd = d.get("displayDate") or {}
        w  = ((d.get("daytimeForecast") or {}).get("wind") or {}).get("speed") or {}
        out.append({
            "date": f"{dd.get('year','')}-{str(dd.get('month','')).zfill(2)}-{str(dd.get('day','')).zfill(2)}",
            "tmax": (d.get("maxTemperature") or {}).get("degrees"),
            "tmin": (d.get("minTemperature") or {}).get("degrees"),
            "wind": w.get("value"),
            "humidity_day": (d.get("daytimeForecast") or {}).get("relativeHumidity"),
            "cloud_day": (d.get("daytimeForecast") or {}).get("cloudCover"),
        })
    return out

# ================== Web scraping: Inside Airbnb average price ==================
def _ascii(s: str) -> str:
    """Normalize/strip accents for fuzzy matching."""
    return unicodedata.normalize("NFKD", s).encode("ascii","ignore").decode("ascii").lower()

def _closest_city_section(soup: BeautifulSoup, want_city: str, want_country: str):
    """
    Return the <h3> city heading element that best matches user's city/country.
    """
    want_city_l = _ascii(want_city)
    want_country_l = _ascii(want_country or "")
    best = None; best_score = -1
    for h3 in soup.select("h3"):
        name = h3.get_text(" ", strip=True)
        name_l = _ascii(name)
        score = 0
        if want_city_l and want_city_l in name_l: score += 3
        if want_country_l and want_country_l in name_l: score += 2
        # token overlap
        overlap = len(set(want_city_l.split()) & set(name_l.split()))
        score += overlap
        if score > best_score:
            best, best_score = h3, score
    return best

def _find_listings_gz_after(h3: BeautifulSoup) -> str | None:
    """
    From a given city heading, find the 'listings.csv.gz' URL in its section.
    """
    cur = h3
    for _ in range(60):  # scan limited siblings until next h3
        cur = cur.find_next_sibling()
        if not cur: break
        if cur.name == "h3": break
        a = cur.find("a", href=True) if hasattr(cur, "find") else None
        if a and a.get("href","").endswith("listings.csv.gz"):
            return a["href"]
    return None

def scrape_airbnb_avg_price(dest: str):
    """
    1) Geocode dest ‚Üí city, country (for matching).
    2) Parse InsideAirbnb index to locate city's listings.csv.gz.
    3) Download CSV (gzip), compute average nightly price.
    Returns dict with 'avg_price', 'currency_hint', 'count', 'source_url'.
    """
    geo = geocode_destination(dest)
    if not geo:
        return {"error": f"Couldn't geocode {dest}"}

    idx = requests.get(INSIDE_AIRBNB_INDEX, headers=HDR, timeout=20)
    idx.raise_for_status()
    soup = BeautifulSoup(idx.text, "lxml")

    h3 = _closest_city_section(soup, geo["city_like"], geo["country"])
    if not h3:
        return {"error": f"No matching city on Inside Airbnb for {geo['city_like']}, {geo['country']}"}

    url = _find_listings_gz_after(h3)
    if not url:
        return {"error": "City found on Inside Airbnb, but no listings.csv.gz link in section."}

    # Download and read CSV (gzip)
    csv_resp = requests.get(url, headers=HDR, timeout=45)
    csv_resp.raise_for_status()
    df = pd.read_csv(io.BytesIO(csv_resp.content), compression="gzip", low_memory=False)

    # Price column cleaning (varies by city; commonly 'price' or 'price_usd')
    price_col = None
    for cand in ["price", "price_usd", "Price", "PRICE"]:
        if cand in df.columns:
            price_col = cand; break
    if not price_col:
        return {"error": "Price column not found in dataset.", "source_url": url}

    s = df[price_col].dropna().astype(str)
    # detect currency symbol from first non-empty string
    cur_hint = None
    for val in s:
        m = re.search(r"[‚Ç¨¬£$]", val)
        if m: cur_hint = m.group(0); break

    # strip everything except digits and dot/comma
    def _to_float(x: str):
        x = x.replace(",", "")
        x = re.sub(r"[^\d\.]", "", x)
        try: return float(x) if x else None
        except: return None

    vals = s.map(_to_float).dropna()
    if vals.empty:
        return {"error": "All prices were empty after cleaning.", "source_url": url}

    avg_price = round(vals.mean(), 2)
    count = int(vals.shape[0])

    return {
        "avg_price": avg_price,
        "currency_hint": cur_hint,  # e.g., $, ¬£, ‚Ç¨
        "count": count,
        "matched_city": h3.get_text(" ", strip=True),
        "source_url": url,
        "note": "Source: Inside Airbnb (CC BY 4.0)",
    }

# ================== Compose UI ==================
def generate_map_and_panels(dest, category, zoom, maptype, iframe_height, units_system, days, include_airbnb):
    # Map
    map_url = build_embed_url(dest or DEFAULT_DEST, category, zoom, maptype)
    map_html = make_iframe(map_url, iframe_height)

    # Weather
    try:
        geo = geocode_destination(dest or DEFAULT_DEST)
        cur = google_weather_current(geo["lat"], geo["lon"], units_system)
        dly = google_weather_daily(geo["lat"], geo["lon"], days, units_system)
    except Exception as e:
        weather_md = f"### Weather\n‚ùå {e}\n"
    else:
        lines = [
            f"### üå§Ô∏è Weather ‚Äî **{geo['display_name']}**",
            f"- **Coords:** {geo['lat']:.4f}, {geo['lon']:.4f}  |  **Country:** {geo.get('country','‚Äî')}",
            f"- **Now:** {cur.get('temp','‚Äî')}¬∞ ({units_system}) ‚Ä¢ {cur.get('condition','‚Äî')}",
            f"- **Feels like:** {cur.get('feels_like','‚Äî')}¬∞ ‚Ä¢ **Humidity:** {cur.get('humidity','‚Äî')}% ‚Ä¢ **Clouds:** {cur.get('cloud_cover','‚Äî')}%",
        ]
        if units_system == "METRIC":
            lines.append(f"- **Wind:** {cur.get('wind_kmh','‚Äî')} km/h (gusts {cur.get('gust_kmh','‚Äî')} km/h)")
        else:
            lines.append(f"- **Wind:** {cur.get('wind_mph','‚Äî')} mph (gusts {cur.get('gust_mph','‚Äî')} mph)")
        if cur.get("pressure_mbar") is not None: lines.append(f"- **Pressure:** {cur['pressure_mbar']} mbar")
        if cur.get("uv_index") is not None: lines.append(f"- **UV index:** {cur['uv_index']}")
        if cur.get("precip_prob") is not None: lines.append(f"- **Precip chance:** {cur['precip_prob']}%")
        if dly:
            lines.append("\n**Next days (max/min, wind):**")
            for d in dly:
                w = d.get("wind","‚Äî")
                unit = "km/h" if units_system=="METRIC" else "mph"
                lines.append(f"- {d['date']}: {d.get('tmax','‚Äî')}¬∞ / {d.get('tmin','‚Äî')}¬∞ ‚Ä¢ wind {w} {unit}")
        lines.append("\n<sub>Weather source: Google Maps Platform Weather API.</sub>")
        weather_md = "\n".join(lines)

    # Airbnb price (scraped)
    airbnb_md = ""
    if include_airbnb:
        try:
            ab = scrape_airbnb_avg_price(dest or DEFAULT_DEST)
            if "error" in ab:
                airbnb_md = f"### üè† Airbnb\n‚ùå {ab['error']}"
                if ab.get("source_url"):
                    airbnb_md += f"\n\n<sub>Dataset: {ab['source_url']}</sub>"
            else:
                sym = ab.get("currency_hint") or ""
                airbnb_md = (
                    "### üè† Airbnb (scraped)\n"
                    f"- **Matched city:** {ab['matched_city']}\n"
                    f"- **Average nightly price (simple mean):** {sym}{ab['avg_price']}\n"
                    f"- **Listings counted:** {ab['count']}\n"
                    f"<sub>{ab['note']}. Dataset: {ab['source_url']}</sub>"
                )
        except Exception as e:
            airbnb_md = f"### üè† Airbnb\n‚ùå Error scraping Inside Airbnb: {e}"

    combined_md = weather_md + ("\n\n" + airbnb_md if airbnb_md else "")
    return map_html, combined_md

with gr.Blocks(title="Holiday Planner ‚Ä¢ Nightlife + Weather + Airbnb (Scraped)") as demo:
    gr.Markdown("# Holiday Planner")
    gr.Markdown(
        "Type a tropical destination and pick a category to find nearby nightlife on the map. "
        "Weather comes from **Google Weather API**, and **average Airbnb price** is scraped from "
        "[Inside Airbnb](https://insideairbnb.com/get-the-data/) (city datasets)."
    )

    with gr.Row():
        dest = gr.Textbox(label="Destination", value=DEFAULT_DEST, placeholder="e.g., Phuket, Thailand")
        category = gr.Dropdown(CATEGORIES, value="nightclubs", label="Category")

    with gr.Row():
        zoom = gr.Slider(3, 20, value=13, step=1, label="Map Zoom")
        maptype = gr.Dropdown(["roadmap","satellite","terrain","hybrid"], value="roadmap", label="Map Type")
        iframe_height = gr.Slider(300, 900, value=600, step=10, label="Map Height (px)")

    with gr.Row():
        units_system = gr.Dropdown(UNITS, value="METRIC", label="Weather Units")
        days = gr.Slider(1, 10, value=5, step=1, label="Forecast Days")
        include_airbnb = gr.Checkbox(value=True, label="Scrape Inside Airbnb average price")

    out_map = gr.HTML(label="Map")
    out_md = gr.Markdown(label="Weather & Airbnb")

    run_btn = gr.Button("Show on Map + Info", variant="primary")
    run_btn.click(
        fn=generate_map_and_panels,
        inputs=[dest, category, zoom, maptype, iframe_height, units_system, days, include_airbnb],
        outputs=[out_map, out_md],
    )

if __name__ == "__main__":
    demo.launch()
