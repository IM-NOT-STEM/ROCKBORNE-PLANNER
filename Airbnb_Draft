from dotenv import load_dotenv, find_dotenv
load_dotenv(find_dotenv(), override=True)

import os, re, io, gzip, urllib.parse, unicodedata, requests, pandas as pd
import gradio as gr
from bs4 import BeautifulSoup
import plotly.graph_objects as go

# ================== Config ==================
DEFAULT_DEST = "Cancún, Mexico"
CATEGORIES = ["nightclubs","restaurants","bars","live music","beach clubs","cafes"]
UNITS = ["METRIC","IMPERIAL"]
INSIDE_AIRBNB_INDEX = "https://insideairbnb.com/get-the-data/"
UA = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36"
HDR = {"User-Agent": UA, "Accept-Language": "en"}

# ================== Google Maps Embed ==================
def build_embed_url(destination: str, category: str, zoom: int = 13, maptype: str = "roadmap") -> str:
    api_key = os.getenv("GOOGLE_MAPS_API_KEY", "")
    if not api_key: return ""
    q = f"{category} near {destination}".strip()
    q_enc = urllib.parse.quote(q)
    return f"https://www.google.com/maps/embed/v1/search?key={api_key}&q={q_enc}&zoom={zoom}&maptype={maptype}"

def make_iframe(url: str, height: int = 600) -> str:
    if not url:
        return "<div style='color:red;padding:1rem'>Error: Missing GOOGLE_MAPS_API_KEY environment variable.</div>"
    return f"""<iframe width="100%" height="{height}" frameborder="0" style="border:0"
      referrerpolicy="no-referrer-when-downgrade" allowfullscreen src="{url}"></iframe>"""

# ================== Geocode (OSM Nominatim) ==================
def geocode_destination(dest: str):
    r = requests.get(
        "https://nominatim.openstreetmap.org/search",
        params={"q": dest, "format": "json", "limit": 1, "addressdetails": 1},
        headers={"User-Agent": "holiday-planner/1.0"},
        timeout=15,
    )
    r.raise_for_status()
    arr = r.json()
    if not arr: return None
    x = arr[0]; addr = x.get("address", {})
    return {
        "lat": float(x["lat"]), "lon": float(x["lon"]),
        "display_name": x.get("display_name", dest),
        "country": addr.get("country",""), "country_code": (addr.get("country_code") or "").upper(),
        "city_like": addr.get("city") or addr.get("town") or addr.get("village") or dest
    }

# ================== Google Weather API (no scraping) ==================
def _gw_key():
    k = os.getenv("GOOGLE_MAPS_API_KEY", "")
    if not k: raise RuntimeError("GOOGLE_MAPS_API_KEY not set")
    return k

def google_weather_current(lat: float, lon: float, units_system="METRIC"):
    url = "https://weather.googleapis.com/v1/currentConditions:lookup"
    r = requests.get(url, params={
        "key": _gw_key(),
        "location.latitude": lat,
        "location.longitude": lon,
        "unitsSystem": units_system,
    }, timeout=15)
    r.raise_for_status()
    j = r.json()
    wind = (j.get("wind") or {})
    speed = (wind.get("speed") or {}).get("value")
    gust  = (wind.get("gust") or {}).get("value")
    out = {
        "temp": (j.get("temperature") or {}).get("degrees"),
        "feels_like": (j.get("feelsLikeTemperature") or {}).get("degrees"),
        "humidity": j.get("relativeHumidity"),
        "cloud_cover": j.get("cloudCover"),
        "condition": ((j.get("weatherCondition") or {}).get("description") or {}).get("text"),
        "wind_kmh": speed if units_system=="METRIC" else None,
        "wind_mph": speed if units_system=="IMPERIAL" else None,
        "gust_kmh": gust if units_system=="METRIC" else None,
        "gust_mph": gust if units_system=="IMPERIAL" else None,
        "pressure_mbar": (j.get("airPressure") or {}).get("meanSeaLevelMillibars"),
        "uv_index": j.get("uvIndex"),
        "precip_prob": ((j.get("precipitation") or {}).get("probability") or {}).get("percent"),
    }
    return out

def google_weather_daily(lat: float, lon: float, days=5, units_system="METRIC"):
    url = "https://weather.googleapis.com/v1/forecast/days:lookup"
    r = requests.get(url, params={
        "key": _gw_key(),
        "location.latitude": lat,
        "location.longitude": lon,
        "days": max(1, min(days, 10)),
        "unitsSystem": units_system,
    }, timeout=15)
    r.raise_for_status()
    j = r.json()
    out = []
    for d in j.get("forecastDays", []):
        dd = d.get("displayDate") or {}
        w  = ((d.get("daytimeForecast") or {}).get("wind") or {}).get("speed") or {}
        out.append({
            "date": f"{dd.get('year','')}-{str(dd.get('month','')).zfill(2)}-{str(dd.get('day','')).zfill(2)}",
            "tmax": (d.get("maxTemperature") or {}).get("degrees"),
            "tmin": (d.get("minTemperature") or {}).get("degrees"),
            "wind": w.get("value"),
            "humidity_day": (d.get("daytimeForecast") or {}).get("relativeHumidity"),
            "cloud_day": (d.get("daytimeForecast") or {}).get("cloudCover"),
        })
    return out

# ================== Web scraping: Inside Airbnb -> GBP + median + histogram ==================
def _ascii(s: str) -> str:
    return unicodedata.normalize("NFKD", s).encode("ascii","ignore").decode("ascii").lower()

def _closest_city_section(soup: BeautifulSoup, want_city: str, want_country: str):
    want_city_l = _ascii(want_city)
    want_country_l = _ascii(want_country or "")
    best = None; best_score = -1
    for h3 in soup.select("h3"):
        name = h3.get_text(" ", strip=True)
        name_l = _ascii(name)
        score = 0
        if want_city_l and want_city_l in name_l: score += 3
        if want_country_l and want_country_l in name_l: score += 2
        overlap = len(set(want_city_l.split()) & set(name_l.split()))
        score += overlap
        if score > best_score:
            best, best_score = h3, score
    return best

def _find_listings_gz_after(h3: BeautifulSoup) -> str | None:
    cur = h3
    for _ in range(60):
        cur = cur.find_next_sibling()
        if not cur: break
        if cur.name == "h3": break
        a = cur.find("a", href=True) if hasattr(cur, "find") else None
        if a and a.get("href","").endswith("listings.csv.gz"):
            return a["href"]
    return None

# --- FX to GBP (Frankfurter API) ---
def fx_to_gbp(amount: float, currency_code: str | None, fallback_symbol: str | None) -> float | None:
    """
    Convert 'amount' to GBP given currency code or symbol.
    Supports: GBP, USD, EUR by default (cheap & cheerful).
    """
    # If already GBP, done.
    if currency_code == "GBP" or fallback_symbol == "£":
        return amount
    # Infer from symbol if code missing:
    code = currency_code or {"$": "USD", "€": "EUR", "£": "GBP"}.get(fallback_symbol or "", None)
    if not code:  # unknown currency; can't safely convert
        return None
    if code == "GBP":
        return amount
    try:
        r = requests.get(
            "https://api.frankfurter.app/latest",
            params={"from": code, "to": "GBP"},
            timeout=10
        )
        r.raise_for_status()
        rate = (r.json().get("rates") or {}).get("GBP")
        return round(amount * float(rate), 2) if rate else None
    except Exception:
        return None

def _detect_symbol_and_code(series_str: pd.Series) -> tuple[str|None, str|None]:
    sym = None
    for val in series_str:
        m = re.search(r"[€£$]", val or "")
        if m:
            sym = m.group(0)
            break
    code = {"$": "USD", "€": "EUR", "£": "GBP"}.get(sym or "", None)
    return sym, code

def scrape_airbnb_stats_gbp(dest: str):
    """
    Scrape InsideAirbnb dataset for the destination, compute:
      - mean GBP, median GBP, count
      - price distribution (GBP) for histogram (clipped to 5th–95th percentiles)
    """
    geo = geocode_destination(dest)
    if not geo:
        return {"error": f"Couldn't geocode {dest}"}

    idx = requests.get(INSIDE_AIRBNB_INDEX, headers=HDR, timeout=20)
    idx.raise_for_status()
    soup = BeautifulSoup(idx.text, "lxml")

    h3 = _closest_city_section(soup, geo["city_like"], geo["country"])
    if not h3:
        return {"error": f"No matching city on Inside Airbnb for {geo['city_like']}, {geo['country']}"}

    url = _find_listings_gz_after(h3)
    if not url:
        return {"error": "City found on Inside Airbnb, but no listings.csv.gz link in section."}

    csv_resp = requests.get(url, headers=HDR, timeout=60)
    csv_resp.raise_for_status()
    df = pd.read_csv(io.BytesIO(csv_resp.content), compression="gzip", low_memory=False)

    # Pick price column
    price_col = None
    for cand in ["price", "price_usd", "Price", "PRICE"]:
        if cand in df.columns:
            price_col = cand; break
    if not price_col:
        return {"error": "Price column not found in dataset.", "source_url": url}

    sraw = df[price_col].dropna().astype(str)
    sym_hint, code_hint = _detect_symbol_and_code(sraw)

    # Clean numeric price
    def _to_float(x: str):
        x = x.replace(",", "")
        x = re.sub(r"[^\d\.]", "", x)
        try: return float(x) if x else None
        except: return None

    vals = sraw.map(_to_float).dropna()
    if vals.empty:
        return {"error": "All prices were empty after cleaning.", "source_url": url}

    # If price_usd → code is USD
    if price_col.lower() == "price_usd":
        code_hint = "USD"

    # Convert each value to GBP
    # We’ll fetch a single rate per run; that’s fine for a quick estimate.
    rate_series = []
    gbp_vals = []
    # Pre-fetch a rate if code_hint known and not GBP
    pre_rate = None
    if (code_hint and code_hint != "GBP"):
        try:
            r = requests.get("https://api.frankfurter.app/latest", params={"from": code_hint, "to": "GBP"}, timeout=10)
            r.raise_for_status()
            pre_rate = (r.json().get("rates") or {}).get("GBP")
        except Exception:
            pre_rate = None

    for v in vals:
        if code_hint == "GBP":
            gbp_vals.append(v)
        elif pre_rate:
            gbp_vals.append(round(v * float(pre_rate), 2))
        else:
            # fall back to per-item (symbol-based) conversion
            cv = fx_to_gbp(v, code_hint, sym_hint)
            if cv is not None:
                gbp_vals.append(cv)

    gbp_series = pd.Series(gbp_vals, dtype="float64").dropna()
    if gbp_series.empty:
        return {"error": "Could not convert prices to GBP.", "source_url": url}

    # Trim outliers for distribution (5th–95th percentile)
    lo, hi = gbp_series.quantile(0.05), gbp_series.quantile(0.95)
    gbp_clipped = gbp_series[(gbp_series >= lo) & (gbp_series <= hi)]

    stats = {
        "count": int(len(gbp_series)),
        "mean_gbp": round(float(gbp_series.mean()), 2),
        "median_gbp": round(float(gbp_series.median()), 2),
        "p05_gbp": round(float(lo), 2),
        "p95_gbp": round(float(hi), 2),
        "matched_city": h3.get_text(" ", strip=True),
        "source_url": url,
        "currency": "GBP",
        "note": "Source: Inside Airbnb (CC BY 4.0). FX by frankfurter.app",
        "hist_values": gbp_clipped.tolist(),
    }
    return stats

def make_histogram(values_gbp: list[float]) -> go.Figure:
    fig = go.Figure()
    fig.add_trace(go.Histogram(
        x=values_gbp,
        nbinsx=40,
        marker_color="#6366f1",
        opacity=0.85,
        name="Nightly price (GBP)"
    ))
    fig.update_layout(
        template="plotly_white",
        title="Nightly Airbnb price distribution (GBP, 5–95% trimmed)",
        xaxis_title="£ per night",
        yaxis_title="Listings",
        height=360,
        bargap=0.05,
    )
    return fig

# ================== Compose UI ==================
def generate_map_and_panels(dest, category, zoom, maptype, iframe_height, units_system, days, include_airbnb):
    # Map
    map_url = build_embed_url(dest or DEFAULT_DEST, category, zoom, maptype)
    map_html = make_iframe(map_url, iframe_height)

    # Weather
    try:
        geo = geocode_destination(dest or DEFAULT_DEST)
        cur = google_weather_current(geo["lat"], geo["lon"], units_system)
        dly = google_weather_daily(geo["lat"], geo["lon"], days, units_system)
    except Exception as e:
        weather_md = f"### Weather\n❌ {e}\n"
    else:
        lines = [
            f"### 🌤️ Weather — **{geo['display_name']}**",
            f"- **Coords:** {geo['lat']:.4f}, {geo['lon']:.4f}  |  **Country:** {geo.get('country','—')}",
            f"- **Now:** {cur.get('temp','—')}° ({units_system}) • {cur.get('condition','—')}",
            f"- **Feels like:** {cur.get('feels_like','—')}° • **Humidity:** {cur.get('humidity','—')}% • **Clouds:** {cur.get('cloud_cover','—')}%",
        ]
        if units_system == "METRIC":
            lines.append(f"- **Wind:** {cur.get('wind_kmh','—')} km/h (gusts {cur.get('gust_kmh','—')} km/h)")
        else:
            lines.append(f"- **Wind:** {cur.get('wind_mph','—')} mph (gusts {cur.get('gust_mph','—')} mph)")
        if cur.get("pressure_mbar") is not None: lines.append(f"- **Pressure:** {cur['pressure_mbar']} mbar")
        if cur.get("uv_index") is not None: lines.append(f"- **UV index:** {cur['uv_index']}")
        if cur.get("precip_prob") is not None: lines.append(f"- **Precip chance:** {cur['precip_prob']}%")
        if dly:
            lines.append("\n**Next days (max/min, wind):**")
            for d in dly:
                w = d.get("wind","—")
                unit = "km/h" if units_system=="METRIC" else "mph"
                lines.append(f"- {d['date']}: {d.get('tmax','—')}° / {d.get('tmin','—')}° • wind {w} {unit}")
        lines.append("\n<sub>Weather source: Google Maps Platform Weather API.</sub>")
        weather_md = "\n".join(lines)

    # Airbnb (GBP + median + histogram)
    hist = go.Figure()
    airbnb_md = ""
    if include_airbnb:
        try:
            ab = scrape_airbnb_stats_gbp(dest or DEFAULT_DEST)
            if "error" in ab:
                airbnb_md = f"### 🏠 Airbnb\n❌ {ab['error']}"
                if ab.get("source_url"):
                    airbnb_md += f"\n\n<sub>Dataset: {ab['source_url']}</sub>"
            else:
                airbnb_md = (
                    "### 🏠 Airbnb (scraped)\n"
                    f"- **Matched city:** {ab['matched_city']}\n"
                    f"- **Listings counted:** {ab['count']}\n"
                    f"- **Average nightly (mean):** £{ab['mean_gbp']}\n"
                    f"- **Median nightly:** £{ab['median_gbp']}\n"
                    f"- **5th–95th percentile:** £{ab['p05_gbp']} – £{ab['p95_gbp']}\n"
                    f"<sub>{ab['note']}. Dataset: {ab['source_url']}</sub>"
                )
                hist = make_histogram(ab["hist_values"])
        except Exception as e:
            airbnb_md = f"### 🏠 Airbnb\n❌ Error scraping Inside Airbnb: {e}"

    combined_md = weather_md + ("\n\n" + airbnb_md if airbnb_md else "")
    return map_html, combined_md, hist

with gr.Blocks(title="Holiday Planner • Nightlife + Weather + Airbnb (GBP)") as demo:
    gr.Markdown("# Holiday Planner")
    gr.Markdown(
        "Nightlife map + Google Weather API + **Inside Airbnb (scraped)** pricing. "
        "Prices are converted to **GBP**, with **median** and a **distribution** chart."
    )

    with gr.Row():
        dest = gr.Textbox(label="Destination", value=DEFAULT_DEST, placeholder="e.g., Phuket, Thailand")
        category = gr.Dropdown(CATEGORIES, value="nightclubs", label="Category")

    with gr.Row():
        zoom = gr.Slider(3, 20, value=13, step=1, label="Map Zoom")
        maptype = gr.Dropdown(["roadmap","satellite","terrain","hybrid"], value="roadmap", label="Map Type")
        iframe_height = gr.Slider(300, 900, value=600, step=10, label="Map Height (px)")

    with gr.Row():
        units_system = gr.Dropdown(UNITS, value="METRIC", label="Weather Units")
        days = gr.Slider(1, 10, value=5, step=1, label="Forecast Days")
        include_airbnb = gr.Checkbox(value=True, label="Scrape Inside Airbnb pricing (GBP)")

    out_map = gr.HTML(label="Map")
    out_md = gr.Markdown(label="Weather & Airbnb (GBP)")
    out_hist = gr.Plot(label="Airbnb price distribution (GBP)")

    run_btn = gr.Button("Show on Map + Info", variant="primary")
    run_btn.click(
        fn=generate_map_and_panels,
        inputs=[dest, category, zoom, maptype, iframe_height, units_system, days, include_airbnb],
        outputs=[out_map, out_md, out_hist],
    )

if __name__ == "__main__":
    demo.launch()
